---
title: "ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆ"
description: "ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆã¨é‹ç”¨ã«é–¢ã™ã‚‹æƒ…å ±"
order: 8
---

# ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆãƒ•ãƒ­ãƒ¼è¨­å®š

## 1. ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆæ¦‚è¦

### 1.1 ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆãƒ•ãƒ­ãƒ¼

```mermaid
graph TD
    A[é–‹ç™º] --> B[ãƒ†ã‚¹ãƒˆ]
    B --> C[ã‚¹ãƒ†ãƒ¼ã‚¸ãƒ³ã‚°]
    C --> D[æœ¬ç•ª]
    B -.-> A
    C -.-> B
```

### 1.2 ç’°å¢ƒæ§‹æˆ
- é–‹ç™ºç’°å¢ƒï¼ˆDevelopmentï¼‰
- ãƒ†ã‚¹ãƒˆç’°å¢ƒï¼ˆTestingï¼‰
- ã‚¹ãƒ†ãƒ¼ã‚¸ãƒ³ã‚°ç’°å¢ƒï¼ˆStagingï¼‰
- æœ¬ç•ªç’°å¢ƒï¼ˆProductionï¼‰

## 2. CI/CD ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³

### 2.1 GitHub Actionsè¨­å®š

```yaml
# .github/workflows/ci.yml
name: CI/CD Pipeline

on:
  push:
    branches: [main, develop]
  pull_request:
    branches: [main, develop]

jobs:
  test:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - uses: oven-sh/setup-bun@v1
      
      - name: Install dependencies
        run: bun install
        
      - name: Run tests
        run: bun test
        
      - name: Run lint
        run: bun run lint
        
  build:
    needs: test
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - uses: oven-sh/setup-bun@v1
      
      - name: Install dependencies
        run: bun install
        
      - name: Build
        run: bun run build
        
      - name: Upload build artifacts
        uses: actions/upload-artifact@v3
        with:
          name: build
          path: .next
          
  deploy-staging:
    needs: build
    if: github.ref == 'refs/heads/develop'
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - uses: actions/download-artifact@v3
        with:
          name: build
          
      - name: Deploy to Vercel (Staging)
        uses: amondnet/vercel-action@v25
        with:
          vercel-token: ${{ secrets.VERCEL_TOKEN }}
          vercel-org-id: ${{ secrets.VERCEL_ORG_ID }}
          vercel-project-id: ${{ secrets.VERCEL_PROJECT_ID }}
          vercel-args: '--prebuilt --prod'
          
  deploy-production:
    needs: build
    if: github.ref == 'refs/heads/main'
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - uses: actions/download-artifact@v3
        with:
          name: build
          
      - name: Deploy to Vercel (Production)
        uses: amondnet/vercel-action@v25
        with:
          vercel-token: ${{ secrets.VERCEL_TOKEN }}
          vercel-org-id: ${{ secrets.VERCEL_ORG_ID }}
          vercel-project-id: ${{ secrets.VERCEL_PROJECT_ID }}
          vercel-args: '--prebuilt --prod'
```

### 2.2 ç’°å¢ƒå¤‰æ•°ã®ç®¡ç†

```typescript
// lib/config/env.ts
import { z } from 'zod'

const envSchema = z.object({
  // Next.js
  NEXT_PUBLIC_APP_URL: z.string().url(),
  
  // Supabase
  NEXT_PUBLIC_SUPABASE_URL: z.string().url(),
  NEXT_PUBLIC_SUPABASE_ANON_KEY: z.string(),
  SUPABASE_SERVICE_ROLE_KEY: z.string(),
  
  // GitHub
  GITHUB_ACCESS_TOKEN: z.string(),
  
  // Redis
  UPSTASH_REDIS_URL: z.string().url(),
  UPSTASH_REDIS_TOKEN: z.string(),
})

declare global {
  namespace NodeJS {
    interface ProcessEnv extends z.infer<typeof envSchema> {}
  }
}

export function validateEnv() {
  try {
    envSchema.parse(process.env)
  } catch (error) {
    console.error('Invalid environment variables:', error)
    process.exit(1)
  }
}
```

## 3. ã‚¤ãƒ³ãƒ•ãƒ©ã‚¹ãƒˆãƒ©ã‚¯ãƒãƒ£è¨­å®š

### 3.1 Vercelè¨­å®š

```json
// vercel.json
{
  "version": 2,
  "builds": [
    {
      "src": "package.json",
      "use": "@vercel/next"
    }
  ],
  "routes": [
    {
      "src": "/(.*)",
      "dest": "/$1"
    }
  ],
  "env": {
    "NEXT_PUBLIC_APP_URL": "@next_public_app_url",
    "NEXT_PUBLIC_SUPABASE_URL": "@next_public_supabase_url",
    "NEXT_PUBLIC_SUPABASE_ANON_KEY": "@next_public_supabase_anon_key"
  }
}
```

### 3.2 Supabaseè¨­å®š

```sql
-- supabase/config.toml
[api]
enabled = true
port = 54321
schemas = ["public", "storage"]
extra_search_path = ["public", "extensions"]
max_rows = 1000

[db]
port = 54322
shadow_port = 54320
major_version = 15

[studio]
enabled = true
port = 54323
api_url = "http://localhost:54321"

[storage]
enabled = true
file_size_limit = "50MB"
```

## 4. ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆæ‰‹é †

### 4.1 æœ¬ç•ªãƒ‡ãƒ—ãƒ­ã‚¤æ‰‹é †

```bash
#!/bin/bash
# scripts/deploy-production.sh

# ç’°å¢ƒå¤‰æ•°ã®æ¤œè¨¼
bun run validate-env

# ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
bun run migrate

# ãƒ“ãƒ«ãƒ‰
bun run build

# ãƒ‡ãƒ—ãƒ­ã‚¤
vercel deploy --prod
```

### 4.2 ãƒ­ãƒ¼ãƒ«ãƒãƒƒã‚¯æ‰‹é †

```bash
#!/bin/bash
# scripts/rollback.sh

# å‰å›ã®ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆã«ãƒ­ãƒ¼ãƒ«ãƒãƒƒã‚¯
vercel rollback

# ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®ãƒ­ãƒ¼ãƒ«ãƒãƒƒã‚¯
bun run migrate:down
```

## 5. ç›£è¦–ã¨ã‚¢ãƒ©ãƒ¼ãƒˆ

### 5.1 ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ¢ãƒ‹ã‚¿ãƒªãƒ³ã‚°

```typescript
// lib/monitoring/performance.ts
export function trackPerformance() {
  if (typeof window === 'undefined') return

  // Core Web Vitals
  const vitals = {
    FCP: 0,
    LCP: 0,
    CLS: 0,
    FID: 0,
  }

  new PerformanceObserver((entryList) => {
    for (const entry of entryList.getEntries()) {
      vitals[entry.name] = entry.value
    }
  }).observe({ entryTypes: ['web-vital'] })

  // ã‚«ã‚¹ã‚¿ãƒ ãƒ¡ãƒˆãƒªã‚¯ã‚¹
  performance.mark('app-ready')
}
```

### 5.2 ã‚¨ãƒ©ãƒ¼ç›£è¦–

```typescript
// lib/monitoring/error.ts
interface ErrorEvent {
  message: string
  stack?: string
  context?: Record<string, unknown>
  timestamp: string
}

export async function trackError(error: Error, context?: Record<string, unknown>) {
  const errorEvent: ErrorEvent = {
    message: error.message,
    stack: error.stack,
    context,
    timestamp: new Date().toISOString(),
  }

  // ã‚¨ãƒ©ãƒ¼ã®è¨˜éŒ²
  console.error('Error:', errorEvent)

  // ã‚¢ãƒ©ãƒ¼ãƒˆã®é€ä¿¡ï¼ˆé‡å¤§ãªã‚¨ãƒ©ãƒ¼ã®å ´åˆï¼‰
  if (isCriticalError(error)) {
    await sendAlert(errorEvent)
  }
}

async function sendAlert(event: ErrorEvent) {
  // Slackãªã©ã¸ã®é€šçŸ¥
  const webhook = process.env.SLACK_WEBHOOK_URL
  if (webhook) {
    await fetch(webhook, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
      },
      body: JSON.stringify({
        text: `ğŸš¨ Critical Error:\n${event.message}\n\`\`\`${event.stack}\`\`\``,
      }),
    })
  }
}
```

## 6. ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã¨å¾©å…ƒ

### 6.1 è‡ªå‹•ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—è¨­å®š

```typescript
// lib/backup/scheduler.ts
import { CronJob } from 'cron'
import { createClient } from '@supabase/supabase-js'

export function setupBackupScheduler() {
  // æ¯æ—¥æ·±å¤œ3æ™‚ã«ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚’å®Ÿè¡Œ
  new CronJob('0 3 * * *', async () => {
    const timestamp = new Date().toISOString()
    const supabase = createClient(
      process.env.SUPABASE_URL!,
      process.env.SUPABASE_SERVICE_ROLE_KEY!
    )

    // ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—
    await backupDatabase(supabase, timestamp)

    // ãƒ¡ãƒ‡ã‚£ã‚¢ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—
    await backupMedia(supabase, timestamp)

    console.log(`Backup completed: ${timestamp}`)
  }).start()
}

async function backupDatabase(supabase: any, timestamp: string) {
  // ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®ãƒ€ãƒ³ãƒ—ã‚’ä½œæˆ
  const { data, error } = await supabase.rpc('backup_database', {
    backup_name: `backup_${timestamp}.sql`,
  })

  if (error) throw error

  // ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¯ãƒ©ã‚¦ãƒ‰ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ã«ä¿å­˜
  await supabase.storage
    .from('backups')
    .upload(`database/${timestamp}.sql`, data)
}

async function backupMedia(supabase: any, timestamp: string) {
  // ãƒ¡ãƒ‡ã‚£ã‚¢ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒªã‚¹ãƒˆã‚’å–å¾—
  const { data: files } = await supabase.storage
    .from('media')
    .list()

  // å„ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—
  for (const file of files) {
    const { data } = await supabase.storage
      .from('media')
      .download(file.name)

    await supabase.storage
      .from('backups')
      .upload(`media/${timestamp}/${file.name}`, data)
  }
}
```

### 6.2 å¾©å…ƒæ‰‹é †

```typescript
// lib/backup/restore.ts
export async function restoreFromBackup(timestamp: string) {
  const supabase = createClient(
    process.env.SUPABASE_URL!,
    process.env.SUPABASE_SERVICE_ROLE_KEY!
  )

  // ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®å¾©å…ƒ
  await restoreDatabase(supabase, timestamp)

  // ãƒ¡ãƒ‡ã‚£ã‚¢ãƒ•ã‚¡ã‚¤ãƒ«ã®å¾©å…ƒ
  await restoreMedia(supabase, timestamp)
}

async function restoreDatabase(supabase: any, timestamp: string) {
  // ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ•ã‚¡ã‚¤ãƒ«ã®å–å¾—
  const { data } = await supabase.storage
    .from('backups')
    .download(`database/${timestamp}.sql`)

  // ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®å¾©å…ƒ
  await supabase.rpc('restore_database', {
    backup_file: data,
  })
}

async function restoreMedia(supabase: any, timestamp: string) {
  // ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‹ã‚‰ãƒ¡ãƒ‡ã‚£ã‚¢ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å¾©å…ƒ
  const { data: files } = await supabase.storage
    .from('backups')
    .list(`media/${timestamp}`)

  for (const file of files) {
    const { data } = await supabase.storage
      .from('backups')
      .download(`media/${timestamp}/${file.name}`)

    await supabase.storage
      .from('media')
      .upload(file.name, data, {
        upsert: true,
      })
  }
}
```

## 7. æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—

1. è² è·ãƒ†ã‚¹ãƒˆã®å®Ÿæ–½
2. ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ç›£æŸ»ã®å®Ÿæ–½
3. ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–
4. ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®æ›´æ–° 